{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 03 \u2014 Housing Price Predictions\n",
    "## CSE 450 Machine Learning | Team 8\n",
    "\n",
    "**Team Members**: Dawson, Peter, Tanner\n",
    "\n",
    "**Objective**: Predict King County house prices using XGBoost regression\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold, GridSearchCV\n",
    "from sklearn.metrics import (mean_squared_error, mean_absolute_error,\n",
    "                             r2_score, mean_absolute_percentage_error)\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from xgboost import XGBRegressor\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('husl')\n",
    "%matplotlib inline\n",
    "\n",
    "print('All imports loaded successfully.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/byui-cse/cse450-course/master/data/housing.csv')\n",
    "holdout = pd.read_csv('https://raw.githubusercontent.com/byui-cse/cse450-course/master/data/housing_holdout_test.csv')\n",
    "mini_holdout = pd.read_csv('https://raw.githubusercontent.com/byui-cse/cse450-course/master/data/housing_holdout_test_mini.csv')\n",
    "\n",
    "print(f'Training:     {df.shape[0]:,} rows x {df.shape[1]} cols')\n",
    "print(f'Holdout:      {holdout.shape[0]:,} rows x {holdout.shape[1]} cols')\n",
    "print(f'Mini holdout: {mini_holdout.shape[0]:,} rows x {mini_holdout.shape[1]} cols')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values\n",
    "missing = df.isnull().sum()\n",
    "print('Missing values:')\n",
    "if missing.sum() > 0:\n",
    "    print(missing[missing > 0])\n",
    "else:\n",
    "    print('None found \\u2014 dataset is clean.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target variable distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "axes[0].hist(df['price'], bins=50, edgecolor='black', alpha=0.7, color='steelblue')\n",
    "axes[0].set_title('House Price Distribution', fontsize=14)\n",
    "axes[0].set_xlabel('Price ($)')\n",
    "axes[0].axvline(df['price'].mean(), color='red', linestyle='--',\n",
    "                label=f'Mean: ${df[\"price\"].mean():,.0f}')\n",
    "axes[0].axvline(df['price'].median(), color='orange', linestyle='--',\n",
    "                label=f'Median: ${df[\"price\"].median():,.0f}')\n",
    "axes[0].legend()\n",
    "\n",
    "axes[1].hist(np.log1p(df['price']), bins=50, edgecolor='black', alpha=0.7, color='steelblue')\n",
    "axes[1].set_title('Log(Price) Distribution', fontsize=14)\n",
    "axes[1].set_xlabel('Log(Price)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print(f'Price range: ${df[\"price\"].min():,.0f} to ${df[\"price\"].max():,.0f}')\n",
    "print(f'Skewness: {df[\"price\"].skew():.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlations with price\n",
    "corr = df.select_dtypes(include=[np.number]).corr()['price'].sort_values(ascending=False)\n",
    "print('Correlation with price:')\n",
    "print(corr.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation heatmap \\u2014 top features\n",
    "top_feats = corr.abs().sort_values(ascending=False).head(12).index\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "sns.heatmap(df[top_feats].corr(), annot=True, fmt='.2f', cmap='RdBu_r',\n",
    "            center=0, ax=ax, square=True)\n",
    "ax.set_title('Correlation Matrix \\u2014 Top 12 Features', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Preprocessing & Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data, is_training=True, train_columns=None):\n",
    "    \"\"\"\n",
    "    Apply identical preprocessing to training and holdout data.\n",
    "    Uses zipcode + lat + long for location (all 3 outperform subsets).\n",
    "    \"\"\"\n",
    "    df = data.copy()\n",
    "\n",
    "    # --- Parse date ---\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df['year_sold'] = df['date'].dt.year\n",
    "    df['month_sold'] = df['date'].dt.month\n",
    "\n",
    "    # --- Age features ---\n",
    "    df['age'] = df['year_sold'] - df['yr_built']\n",
    "    df['renovated'] = (df['yr_renovated'] > 0).astype(int)\n",
    "    df['years_since_renovation'] = np.where(\n",
    "        df['yr_renovated'] > 0,\n",
    "        df['year_sold'] - df['yr_renovated'],\n",
    "        df['age']\n",
    "    )\n",
    "\n",
    "    # --- Derived features ---\n",
    "    df['has_basement'] = (df['sqft_basement'] > 0).astype(int)\n",
    "    df['total_rooms'] = df['bedrooms'] + df['bathrooms']\n",
    "    df['living_lot_ratio'] = df['sqft_living'] / df['sqft_lot'].clip(lower=1)\n",
    "    df['sqft_per_room'] = df['sqft_living'] / df['total_rooms'].clip(lower=1)\n",
    "    df['above_ground_ratio'] = df['sqft_above'] / df['sqft_living'].clip(lower=1)\n",
    "\n",
    "    # --- Drop raw columns we replaced ---\n",
    "    drop_cols = ['id', 'date', 'yr_built', 'yr_renovated']\n",
    "    df = df.drop(columns=[c for c in drop_cols if c in df.columns])\n",
    "\n",
    "    # --- Return ---\n",
    "    if is_training:\n",
    "        y = df.pop('price')\n",
    "        return df, y\n",
    "    else:\n",
    "        if 'price' in df.columns:\n",
    "            df = df.drop(columns=['price'])\n",
    "        if train_columns is not None:\n",
    "            for col in train_columns:\n",
    "                if col not in df.columns:\n",
    "                    df[col] = 0\n",
    "            df = df[train_columns]\n",
    "        return df\n",
    "\n",
    "print('Preprocessing function defined.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply to training data\n",
    "X, y = preprocess(df, is_training=True)\n",
    "\n",
    "print(f'Features: {X.shape[1]} columns')\n",
    "print(f'Target: {len(y):,} values')\n",
    "print(f'\\nFeature list:\\n{list(X.columns)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity checks\n",
    "print('Missing values after preprocessing:')\n",
    "miss = X.isnull().sum()\n",
    "print(miss[miss > 0] if miss.sum() > 0 else 'None')\n",
    "print(f'\\nInfinite values: {np.isinf(X.select_dtypes(include=[np.number])).sum().sum()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "print(f'Training set: {X_train.shape[0]:,} rows')\n",
    "print(f'Test set:     {X_test.shape[0]:,} rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, X_test, y_test, name='Model'):\n",
    "    \"\"\"Evaluate a model and return metrics dict.\"\"\"\n",
    "    preds = model.predict(X_test)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "    mae = mean_absolute_error(y_test, preds)\n",
    "    r2 = r2_score(y_test, preds)\n",
    "    mape = mean_absolute_percentage_error(y_test, preds) * 100\n",
    "\n",
    "    print(f'{name}:')\n",
    "    print(f'  RMSE:  ${rmse:,.2f}')\n",
    "    print(f'  MAE:   ${mae:,.2f}')\n",
    "    print(f'  R2:    {r2:.4f}')\n",
    "    print(f'  MAPE:  {mape:.2f}%')\n",
    "    print()\n",
    "    return {\n",
    "        'model': name, 'rmse': rmse, 'mae': mae,\n",
    "        'r2': r2, 'mape': mape, 'preds': preds\n",
    "    }\n",
    "\n",
    "results = {}\n",
    "print('Evaluation function defined.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline: predict mean price\n",
    "class MeanBaseline:\n",
    "    def fit(self, X, y):\n",
    "        self.mean_ = y.mean()\n",
    "        return self\n",
    "    def predict(self, X):\n",
    "        return np.full(len(X), self.mean_)\n",
    "\n",
    "baseline = MeanBaseline().fit(X_train, y_train)\n",
    "results['Baseline'] = evaluate(baseline, X_test, y_test, 'Baseline (Mean)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "results['Linear'] = evaluate(lr, X_test, y_test, 'Linear Regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "rf = RandomForestRegressor(n_estimators=200, max_depth=None, random_state=42, n_jobs=-1)\n",
    "rf.fit(X_train, y_train)\n",
    "results['RF'] = evaluate(rf, X_test, y_test, 'Random Forest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boosting (sklearn)\n",
    "gb = GradientBoostingRegressor(n_estimators=200, learning_rate=0.1, max_depth=5, random_state=42)\n",
    "gb.fit(X_train, y_train)\n",
    "results['GB'] = evaluate(gb, X_test, y_test, 'Gradient Boosting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost (default hyperparameters)\n",
    "xgb_default = XGBRegressor(\n",
    "    n_estimators=500, learning_rate=0.1, max_depth=6,\n",
    "    subsample=0.8, colsample_bytree=0.8,\n",
    "    random_state=42, n_jobs=-1\n",
    ")\n",
    "xgb_default.fit(X_train, y_train)\n",
    "results['XGB_default'] = evaluate(xgb_default, X_test, y_test, 'XGBoost (default)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Hyperparameter Tuning (XGBoost)\n",
    "\n",
    "GridSearchCV to find the best XGBoost parameters. This may take a few minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [300, 500, 800],\n",
    "    'max_depth': [4, 6, 8],\n",
    "    'learning_rate': [0.05, 0.1],\n",
    "    'subsample': [0.8],\n",
    "    'colsample_bytree': [0.8],\n",
    "    'min_child_weight': [3, 5],\n",
    "}\n",
    "\n",
    "print(f'Grid search: {np.prod([len(v) for v in param_grid.values()])} combinations x 3 folds')\n",
    "print('Training...')\n",
    "\n",
    "xgb_grid = GridSearchCV(\n",
    "    XGBRegressor(random_state=42, n_jobs=-1),\n",
    "    param_grid,\n",
    "    cv=3,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "xgb_grid.fit(X_train, y_train)\n",
    "\n",
    "print(f'\\nBest parameters: {xgb_grid.best_params_}')\n",
    "print(f'Best CV RMSE: ${np.sqrt(-xgb_grid.best_score_):,.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the tuned XGBoost\n",
    "best_xgb = xgb_grid.best_estimator_\n",
    "results['XGB_tuned'] = evaluate(best_xgb, X_test, y_test, 'XGBoost (tuned)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5-Fold Cross-Validation on the best model\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_scores = cross_val_score(best_xgb, X, y, cv=kf, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "cv_rmse = np.sqrt(-cv_scores)\n",
    "\n",
    "print('5-Fold Cross-Validation Results:')\n",
    "print(f'  RMSE scores: {[f\"${x:,.0f}\" for x in cv_rmse]}')\n",
    "print(f'  Mean RMSE:   ${cv_rmse.mean():,.2f}')\n",
    "print(f'  Std RMSE:    ${cv_rmse.std():,.2f}')\n",
    "print(f'  CV:          {cv_rmse.std()/cv_rmse.mean()*100:.1f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance from tuned XGBoost\n",
    "importances = pd.Series(best_xgb.feature_importances_, index=X.columns)\n",
    "top_n = 15\n",
    "top_features = importances.nlargest(top_n)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "top_features.sort_values().plot(kind='barh', ax=ax, color='steelblue', edgecolor='black')\n",
    "ax.set_xlabel('Feature Importance (Gain)', fontsize=12)\n",
    "ax.set_title(f'Top {top_n} Price Drivers in House Price Predictions', fontsize=14)\n",
    "ax.tick_params(axis='y', labelsize=11)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('\\nTop 7 Price Drivers:')\n",
    "for i, (feat, imp) in enumerate(importances.nlargest(7).items(), 1):\n",
    "    print(f'  {i}. {feat}: importance = {imp:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare all models side by side\n",
    "comparison = pd.DataFrame([\n",
    "    {k: v for k, v in r.items() if k != 'preds'}\n",
    "    for r in results.values()\n",
    "]).set_index('model')\n",
    "\n",
    "print(comparison.to_string())\n",
    "print()\n",
    "best_model_name = comparison['rmse'].idxmin()\n",
    "print(f'Best model: {best_model_name} (lowest RMSE)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model comparison chart\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "models = comparison.index.tolist()\n",
    "colors = plt.cm.Set2(np.linspace(0, 1, len(models)))\n",
    "\n",
    "axes[0].barh(models, comparison['rmse'], color=colors, edgecolor='black')\n",
    "axes[0].set_xlabel('RMSE ($)')\n",
    "axes[0].set_title('RMSE (lower = better)')\n",
    "\n",
    "axes[1].barh(models, comparison['mae'], color=colors, edgecolor='black')\n",
    "axes[1].set_xlabel('MAE ($)')\n",
    "axes[1].set_title('MAE (lower = better)')\n",
    "\n",
    "axes[2].barh(models, comparison['r2'], color=colors, edgecolor='black')\n",
    "axes[2].set_xlabel('R-squared')\n",
    "axes[2].set_title('R-squared (higher = better)')\n",
    "axes[2].set_xlim(0, 1)\n",
    "\n",
    "plt.suptitle('Model Performance Comparison', fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicted vs Actual\n",
    "preds_test = best_xgb.predict(X_test)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.scatter(y_test / 1e6, preds_test / 1e6, alpha=0.3, s=8, color='#2E86AB')\n",
    "lims = [0, max(y_test.max(), preds_test.max()) / 1e6 * 1.05]\n",
    "ax.plot(lims, lims, 'r--', linewidth=2, alpha=0.8, label='Perfect Prediction')\n",
    "ax.set_xlabel('Actual Price (Millions $)', fontsize=12)\n",
    "ax.set_ylabel('Predicted Price (Millions $)', fontsize=12)\n",
    "ax.set_title('Predicted vs Actual House Prices', fontsize=14, fontweight='bold')\n",
    "ax.set_xlim(lims)\n",
    "ax.set_ylim(lims)\n",
    "ax.set_aspect('equal')\n",
    "ax.legend(fontsize=11)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "r2_val = r2_score(y_test, preds_test)\n",
    "rmse_val = np.sqrt(mean_squared_error(y_test, preds_test))\n",
    "ax.text(0.05, 0.92, f'R-squared = {r2_val:.4f}\\nRMSE = ${rmse_val:,.0f}',\n",
    "        transform=ax.transAxes, fontsize=12,\n",
    "        bbox=dict(boxstyle='round', facecolor='lightyellow', alpha=0.9))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residual distribution\n",
    "residuals = y_test - preds_test\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.hist(residuals / 1000, bins=60, edgecolor='black', alpha=0.7, color='#2E86AB')\n",
    "ax.axvline(0, color='red', linestyle='--', linewidth=2)\n",
    "ax.set_xlabel('Prediction Error (Thousands $)', fontsize=12)\n",
    "ax.set_ylabel('Count', fontsize=12)\n",
    "ax.set_title('Distribution of Prediction Errors', fontsize=14, fontweight='bold')\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "ax.text(0.72, 0.85, f'Mean error: ${residuals.mean():,.0f}\\nMedian error: ${residuals.median():,.0f}',\n",
    "        transform=ax.transAxes, fontsize=11,\n",
    "        bbox=dict(boxstyle='round', facecolor='lightyellow', alpha=0.9))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Holdout Predictions\n",
    "\n",
    "**CRITICAL**: Filename must be `team8-module3-predictions.csv` (DASHES, not underscores!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess holdout data using same function\n",
    "train_columns = X.columns.tolist()\n",
    "holdout_X = preprocess(holdout, is_training=False, train_columns=train_columns)\n",
    "\n",
    "print(f'Holdout features: {holdout_X.shape}')\n",
    "print(f'Training features: {X.shape}')\n",
    "print(f'Columns match: {list(holdout_X.columns) == train_columns}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions and save\n",
    "holdout_preds = best_xgb.predict(holdout_X)\n",
    "\n",
    "submission = pd.DataFrame({'price': holdout_preds})\n",
    "submission.to_csv('team8-module3-predictions.csv', index=False)\n",
    "\n",
    "# VERIFY\n",
    "check = pd.read_csv('team8-module3-predictions.csv')\n",
    "print('=== HOLDOUT VERIFICATION ===')\n",
    "print(f'Filename:        team8-module3-predictions.csv')\n",
    "print(f'Columns:         {list(check.columns)}')\n",
    "print(f'Rows:            {len(check)}')\n",
    "print(f'All same value?  {check[\"price\"].nunique() == 1}  (should be False!)')\n",
    "print(f'Min prediction:  ${check[\"price\"].min():,.2f}')\n",
    "print(f'Max prediction:  ${check[\"price\"].max():,.2f}')\n",
    "print(f'Mean prediction: ${check[\"price\"].mean():,.2f}')\n",
    "print()\n",
    "print('First 10 predictions:')\n",
    "print(check.head(10).to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Mini Holdout Check (PM Checkin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess mini holdout\n",
    "mini_X = preprocess(mini_holdout, is_training=False, train_columns=train_columns)\n",
    "print(f'Mini holdout features: {mini_X.shape}')\n",
    "\n",
    "# Generate predictions\n",
    "mini_preds = best_xgb.predict(mini_X)\n",
    "\n",
    "# Save\n",
    "mini_sub = pd.DataFrame({'price': mini_preds})\n",
    "mini_sub.to_csv('team8-module3-mini-predictions.csv', index=False)\n",
    "\n",
    "# Verify\n",
    "check_mini = pd.read_csv('team8-module3-mini-predictions.csv')\n",
    "print(f'Saved: team8-module3-mini-predictions.csv')\n",
    "print(f'Rows: {len(check_mini)}')\n",
    "print(f'Sample predictions: {check_mini[\"price\"].head().tolist()}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ML Module 03)",
   "language": "python",
   "name": "ml-module03"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3",
   "mimetype": "text/x-python",
   "file_extension": ".py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}